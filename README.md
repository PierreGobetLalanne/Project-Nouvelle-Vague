# Project-Nouvelle-Vague
Creating new musical instrument sounds using LSTM neural networks
Dataset used for the notebook to run is is the NSynth dataset: https://magenta.tensorflow.org/datasets/nsynth
Caution: dataset is large (several tens of Go)

Synopsis of the original paper:
The latest developments of generative machine learning hold great promise in various artistic fields such as literature, visual arts and music. In the latter field in particular, neural networks are being used with increasing success to create melodies, harmonize tunes or transcribe songs into partitions. But neural networks could also be used at a more fundamental level, not to assemble or translate, but to redefine the very palette with which songs are created: instruments. In this scope, we build on recent research ([8], [9]) to create a method for the generation of new musical instrument sounds. Using a comprehensive dataset of audio samples of existing musical instruments, we translate soundwaves into a simplified yet meaningful frequency spectrum representation and use a LSTM neural network to create new instrument timbres. We obtain sounds that have several of the factors that make the tonal richness of acoustic instruments while also bearing interesting and surprising variations. In a survey evaluation, the audio samples we generated score better than both acoustic and electronic instruments on the attributes of pleasantness and originality, while nearly reaching the score of acoustic instruments in realism.
